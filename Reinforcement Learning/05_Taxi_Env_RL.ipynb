{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05- Taxi_Env_RL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we will try to understand and solve the *openaigym* taxi environment, where the can has to pick up and drop the passenger in the correct location."
      ],
      "metadata": {
        "id": "QDKHqjGhlOAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import pickle, os"
      ],
      "metadata": {
        "id": "goW39qjHlfsQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"Taxi-v3\") # creating the environment"
      ],
      "metadata": {
        "id": "6426-NZIlh-8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = env.reset() # resting the environment\n"
      ],
      "metadata": {
        "id": "XEA0fi2Ylw9L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6YnEWVLlzYC",
        "outputId": "d33c7efe-edba-4a9f-b4aa-2dceb38842b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.render() # dispaly the environment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcVD9InTl01E",
        "outputId": "ed60b839-a8d4-43c2-efe9-50b86258658e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|R: |\u001b[43m \u001b[0m: :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_states = env.observation_space.n # possible states in the environment\n",
        "n_actions = env.action_space.n # possible actions for any state in the environment"
      ],
      "metadata": {
        "id": "iHIaf37WlsJP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_actions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo4e6LGbmIiy",
        "outputId": "57eab16d-efe2-4288-87ea-4d450fe0a26e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_states"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ApSyZyYmKRr",
        "outputId": "08debb87-2b2a-445f-bf19-0fdaeec59a2e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.step(3) # take a random step"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqiXulIQmLZi",
        "outputId": "fff11d6b-5593-4216-a0fa-50b243f83b88"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51, -1, False, {'prob': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-a7agndmUiD",
        "outputId": "76891304-0a10-4e0d-fd39-6281b077452b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|R: |\u001b[43m \u001b[0m: :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# running an environment completely randomly\n",
        "\n",
        "state = env.reset()\n",
        "steps = 0\n",
        "g = 0\n",
        "reward = None\n",
        "done = False\n",
        "\n",
        "while reward != 20:\n",
        "  state, reward, done, info = env.step(env.action_space.sample())\n",
        "  steps += 1\n",
        "  g += reward\n",
        "\n",
        "print(f\"Solved in {steps} Steps with a total reward of {g}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU4a6kZNmXZC",
        "outputId": "c42c1c11-1cbf-4597-d1c0-1ccde20d7fcf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solved in 6116 Steps with a total reward of -24203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q-Learning"
      ],
      "metadata": {
        "id": "lzdve4NZoA8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q = np.zeros([n_states, n_actions]) # initailise all zeros Q-Table"
      ],
      "metadata": {
        "id": "PuyWfCXcm8Ex"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 500 # number of episodes to run\n",
        "rewardTracker = []\n",
        "G = 0\n",
        "alpha = 0.618\n",
        "\n",
        "for episode in range(1,episodes+1): # for all episodes\n",
        "  done = False\n",
        "  G, reward = 0,0\n",
        "  state = env.reset() # reset teh environment\n",
        "  while not done:\n",
        "    action = np.argmax(Q[state]) # taking maximum Q-value action\n",
        "    state2, reward, done, info = env.step(action) \n",
        "    Q[state,action] += alpha * ((reward + (np.max(Q[state2]))  - Q[state,action])) # update Q-value\n",
        "    G += reward\n",
        "    state = state2\n",
        "      \n",
        "  if episode % 100 == 0:\n",
        "    print('Episode {} Total Reward: {}'.format(episode,G))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeRZpQx-oFvY",
        "outputId": "06271c9c-c6e1-42b7-e0af-27eaef8098f2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 100 Total Reward: 11\n",
            "Episode 200 Total Reward: 5\n",
            "Episode 300 Total Reward: 8\n",
            "Episode 400 Total Reward: 10\n",
            "Episode 500 Total Reward: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now use the learnt Q-values to solve the environment using optimal policy\n",
        "counter = 0\n",
        "state = env.reset()\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "  # We simply take the action with the highest Q Value\n",
        "  action = np.argmax(Q[state])\n",
        "  state, reward, done, info = env.step(action)\n",
        "  counter += 1"
      ],
      "metadata": {
        "id": "Vjbq7UjLojKN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Solved in {counter} Steps\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfkfHO41o5R-",
        "outputId": "a98f6a06-6662-4010-9db8-3fbb73286b3c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solved in 15 Steps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # saving and loading the learnt table\n",
        "\n",
        "# with open(\"smartTaxi_qTable.pkl\", 'wb') as f:\n",
        "#   pickle.dump(Q, f)\n",
        "\n",
        "# with open(\"smartTaxi_qTable.pkl\", 'rb') as f:\n",
        "#   Qtest = pickle.load(f)"
      ],
      "metadata": {
        "id": "z0_WatTwpEh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SARSA (State Action Reward State Action)"
      ],
      "metadata": {
        "id": "adx3iKQ-riiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploration vs Exploitation\n",
        "def choose_action(state):\n",
        "  action=0\n",
        "  if np.random.uniform(0, 1) < epsilon:\n",
        "      action = env.action_space.sample()\n",
        "  else:\n",
        "      action = np.argmax(Q[state, :])\n",
        "  return action"
      ],
      "metadata": {
        "id": "657QRF73rt-q"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the Q-Table\n",
        "def learn(state, stateNext, reward, action, actionNext):\n",
        "  predict = Q[state, action]\n",
        "  target = reward + gamma * Q[stateNext, actionNext]\n",
        "  Q[state, action] = Q[state, action] + alpha * (target - predict)"
      ],
      "metadata": {
        "id": "yr4OZXhGsEaO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_episodes = 10000\n",
        "epsilon = 0.05\n",
        "alpha = 0.618\n",
        "gamma = 0.9\n",
        "\n",
        "Q = np.zeros((env.observation_space.n, env.action_space.n))"
      ],
      "metadata": {
        "id": "3h77G120sMpd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rewards = 0\n",
        "for episode in range(total_episodes):\n",
        "  counter = 0\n",
        "  state = env.reset()\n",
        "  action = choose_action(state)\n",
        "  done = False\n",
        "  while not done:\n",
        "    stateNext, reward, done, info = env.step(action)\n",
        "    actionNext = choose_action(stateNext)\n",
        "    learn(state, stateNext, reward, action, actionNext)\n",
        "    state = stateNext\n",
        "    action = actionNext"
      ],
      "metadata": {
        "id": "qklIDhKzsUNW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the learnt Q-table\n",
        "state = env.reset()\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "  # We simply take the action with the highest Q Value\n",
        "  action = np.argmax(Q[state])\n",
        "  state, reward, done, info = env.step(action)\n",
        "  env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7USDLoyseR3",
        "outputId": "e7579b2f-ff14-4045-e1ee-ee8364cdbe59"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | :\u001b[43m \u001b[0m: |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : :\u001b[43m \u001b[0m: |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : :\u001b[43m \u001b[0m: : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| :\u001b[43m \u001b[0m: : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "|\u001b[43m \u001b[0m: : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "|\u001b[43m \u001b[0m: | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|\u001b[42mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (Pickup)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "|\u001b[42m_\u001b[0m: | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "|\u001b[42m_\u001b[0m: : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| :\u001b[42m_\u001b[0m: : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : :\u001b[42m_\u001b[0m: : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : :\u001b[42m_\u001b[0m: |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : |\u001b[42m_\u001b[0m: |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35m\u001b[42mB\u001b[0m\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35m\u001b[34;1m\u001b[43mB\u001b[0m\u001b[0m\u001b[0m: |\n",
            "+---------+\n",
            "  (Dropoff)\n"
          ]
        }
      ]
    }
  ]
}