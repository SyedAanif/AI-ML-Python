{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will learn **Incremental Learning**, where model is trained continuously on incoming new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5rk6jbiZtI3X"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vdFsotuFtLG0"
   },
   "outputs": [],
   "source": [
    "iris = sklearn.datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YUIUnfPitI3m"
   },
   "outputs": [],
   "source": [
    "X=iris.data\n",
    "Y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-9UCO5z2tI3y",
    "outputId": "fd51f483-6c26-4553-d351-57ca276a9260"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SIr3epzjtI38",
    "outputId": "f7ff6257-ff06-4911-fcb6-f44b11766799"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2S--PdeGtI4G",
    "outputId": "2237aa17-73d5-42d5-ffdf-04cc38d217e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "minmax_scaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e4_OL3kWtI4O"
   },
   "outputs": [],
   "source": [
    "X=minmax_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "h5UDi5yZtI4W",
    "outputId": "5722f0c6-69bd-4b35-d595-a9b2b576f97a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.66666667, 0.06779661, 0.04166667],\n",
       "       [0.30555556, 0.79166667, 0.11864407, 0.125     ],\n",
       "       [0.08333333, 0.58333333, 0.06779661, 0.08333333],\n",
       "       [0.19444444, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.02777778, 0.375     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
       "       [0.30555556, 0.70833333, 0.08474576, 0.04166667],\n",
       "       [0.13888889, 0.58333333, 0.10169492, 0.04166667],\n",
       "       [0.13888889, 0.41666667, 0.06779661, 0.        ],\n",
       "       [0.        , 0.41666667, 0.01694915, 0.        ],\n",
       "       [0.41666667, 0.83333333, 0.03389831, 0.04166667],\n",
       "       [0.38888889, 1.        , 0.08474576, 0.125     ],\n",
       "       [0.30555556, 0.79166667, 0.05084746, 0.125     ],\n",
       "       [0.22222222, 0.625     , 0.06779661, 0.08333333],\n",
       "       [0.38888889, 0.75      , 0.11864407, 0.08333333],\n",
       "       [0.22222222, 0.75      , 0.08474576, 0.08333333],\n",
       "       [0.30555556, 0.58333333, 0.11864407, 0.04166667],\n",
       "       [0.22222222, 0.70833333, 0.08474576, 0.125     ],\n",
       "       [0.08333333, 0.66666667, 0.        , 0.04166667],\n",
       "       [0.22222222, 0.54166667, 0.11864407, 0.16666667],\n",
       "       [0.13888889, 0.58333333, 0.15254237, 0.04166667],\n",
       "       [0.19444444, 0.41666667, 0.10169492, 0.04166667],\n",
       "       [0.19444444, 0.58333333, 0.10169492, 0.125     ],\n",
       "       [0.25      , 0.625     , 0.08474576, 0.04166667],\n",
       "       [0.25      , 0.58333333, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.10169492, 0.04166667],\n",
       "       [0.13888889, 0.45833333, 0.10169492, 0.04166667],\n",
       "       [0.30555556, 0.58333333, 0.08474576, 0.125     ],\n",
       "       [0.25      , 0.875     , 0.08474576, 0.        ],\n",
       "       [0.33333333, 0.91666667, 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.5       , 0.03389831, 0.04166667],\n",
       "       [0.33333333, 0.625     , 0.05084746, 0.04166667],\n",
       "       [0.16666667, 0.66666667, 0.06779661, 0.        ],\n",
       "       [0.02777778, 0.41666667, 0.05084746, 0.04166667],\n",
       "       [0.22222222, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.625     , 0.05084746, 0.08333333],\n",
       "       [0.05555556, 0.125     , 0.05084746, 0.08333333],\n",
       "       [0.02777778, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.19444444, 0.625     , 0.10169492, 0.20833333],\n",
       "       [0.22222222, 0.75      , 0.15254237, 0.125     ],\n",
       "       [0.13888889, 0.41666667, 0.06779661, 0.08333333],\n",
       "       [0.22222222, 0.75      , 0.10169492, 0.04166667],\n",
       "       [0.08333333, 0.5       , 0.06779661, 0.04166667],\n",
       "       [0.27777778, 0.70833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.54166667, 0.06779661, 0.04166667],\n",
       "       [0.75      , 0.5       , 0.62711864, 0.54166667],\n",
       "       [0.58333333, 0.5       , 0.59322034, 0.58333333],\n",
       "       [0.72222222, 0.45833333, 0.66101695, 0.58333333],\n",
       "       [0.33333333, 0.125     , 0.50847458, 0.5       ],\n",
       "       [0.61111111, 0.33333333, 0.61016949, 0.58333333],\n",
       "       [0.38888889, 0.33333333, 0.59322034, 0.5       ],\n",
       "       [0.55555556, 0.54166667, 0.62711864, 0.625     ],\n",
       "       [0.16666667, 0.16666667, 0.38983051, 0.375     ],\n",
       "       [0.63888889, 0.375     , 0.61016949, 0.5       ],\n",
       "       [0.25      , 0.29166667, 0.49152542, 0.54166667],\n",
       "       [0.19444444, 0.        , 0.42372881, 0.375     ],\n",
       "       [0.44444444, 0.41666667, 0.54237288, 0.58333333],\n",
       "       [0.47222222, 0.08333333, 0.50847458, 0.375     ],\n",
       "       [0.5       , 0.375     , 0.62711864, 0.54166667],\n",
       "       [0.36111111, 0.375     , 0.44067797, 0.5       ],\n",
       "       [0.66666667, 0.45833333, 0.57627119, 0.54166667],\n",
       "       [0.36111111, 0.41666667, 0.59322034, 0.58333333],\n",
       "       [0.41666667, 0.29166667, 0.52542373, 0.375     ],\n",
       "       [0.52777778, 0.08333333, 0.59322034, 0.58333333],\n",
       "       [0.36111111, 0.20833333, 0.49152542, 0.41666667],\n",
       "       [0.44444444, 0.5       , 0.6440678 , 0.70833333],\n",
       "       [0.5       , 0.33333333, 0.50847458, 0.5       ],\n",
       "       [0.55555556, 0.20833333, 0.66101695, 0.58333333],\n",
       "       [0.5       , 0.33333333, 0.62711864, 0.45833333],\n",
       "       [0.58333333, 0.375     , 0.55932203, 0.5       ],\n",
       "       [0.63888889, 0.41666667, 0.57627119, 0.54166667],\n",
       "       [0.69444444, 0.33333333, 0.6440678 , 0.54166667],\n",
       "       [0.66666667, 0.41666667, 0.6779661 , 0.66666667],\n",
       "       [0.47222222, 0.375     , 0.59322034, 0.58333333],\n",
       "       [0.38888889, 0.25      , 0.42372881, 0.375     ],\n",
       "       [0.33333333, 0.16666667, 0.47457627, 0.41666667],\n",
       "       [0.33333333, 0.16666667, 0.45762712, 0.375     ],\n",
       "       [0.41666667, 0.29166667, 0.49152542, 0.45833333],\n",
       "       [0.47222222, 0.29166667, 0.69491525, 0.625     ],\n",
       "       [0.30555556, 0.41666667, 0.59322034, 0.58333333],\n",
       "       [0.47222222, 0.58333333, 0.59322034, 0.625     ],\n",
       "       [0.66666667, 0.45833333, 0.62711864, 0.58333333],\n",
       "       [0.55555556, 0.125     , 0.57627119, 0.5       ],\n",
       "       [0.36111111, 0.41666667, 0.52542373, 0.5       ],\n",
       "       [0.33333333, 0.20833333, 0.50847458, 0.5       ],\n",
       "       [0.33333333, 0.25      , 0.57627119, 0.45833333],\n",
       "       [0.5       , 0.41666667, 0.61016949, 0.54166667],\n",
       "       [0.41666667, 0.25      , 0.50847458, 0.45833333],\n",
       "       [0.19444444, 0.125     , 0.38983051, 0.375     ],\n",
       "       [0.36111111, 0.29166667, 0.54237288, 0.5       ],\n",
       "       [0.38888889, 0.41666667, 0.54237288, 0.45833333],\n",
       "       [0.38888889, 0.375     , 0.54237288, 0.5       ],\n",
       "       [0.52777778, 0.375     , 0.55932203, 0.5       ],\n",
       "       [0.22222222, 0.20833333, 0.33898305, 0.41666667],\n",
       "       [0.38888889, 0.33333333, 0.52542373, 0.5       ],\n",
       "       [0.55555556, 0.54166667, 0.84745763, 1.        ],\n",
       "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
       "       [0.77777778, 0.41666667, 0.83050847, 0.83333333],\n",
       "       [0.55555556, 0.375     , 0.77966102, 0.70833333],\n",
       "       [0.61111111, 0.41666667, 0.81355932, 0.875     ],\n",
       "       [0.91666667, 0.41666667, 0.94915254, 0.83333333],\n",
       "       [0.16666667, 0.20833333, 0.59322034, 0.66666667],\n",
       "       [0.83333333, 0.375     , 0.89830508, 0.70833333],\n",
       "       [0.66666667, 0.20833333, 0.81355932, 0.70833333],\n",
       "       [0.80555556, 0.66666667, 0.86440678, 1.        ],\n",
       "       [0.61111111, 0.5       , 0.69491525, 0.79166667],\n",
       "       [0.58333333, 0.29166667, 0.72881356, 0.75      ],\n",
       "       [0.69444444, 0.41666667, 0.76271186, 0.83333333],\n",
       "       [0.38888889, 0.20833333, 0.6779661 , 0.79166667],\n",
       "       [0.41666667, 0.33333333, 0.69491525, 0.95833333],\n",
       "       [0.58333333, 0.5       , 0.72881356, 0.91666667],\n",
       "       [0.61111111, 0.41666667, 0.76271186, 0.70833333],\n",
       "       [0.94444444, 0.75      , 0.96610169, 0.875     ],\n",
       "       [0.94444444, 0.25      , 1.        , 0.91666667],\n",
       "       [0.47222222, 0.08333333, 0.6779661 , 0.58333333],\n",
       "       [0.72222222, 0.5       , 0.79661017, 0.91666667],\n",
       "       [0.36111111, 0.33333333, 0.66101695, 0.79166667],\n",
       "       [0.94444444, 0.33333333, 0.96610169, 0.79166667],\n",
       "       [0.55555556, 0.29166667, 0.66101695, 0.70833333],\n",
       "       [0.66666667, 0.54166667, 0.79661017, 0.83333333],\n",
       "       [0.80555556, 0.5       , 0.84745763, 0.70833333],\n",
       "       [0.52777778, 0.33333333, 0.6440678 , 0.70833333],\n",
       "       [0.5       , 0.41666667, 0.66101695, 0.70833333],\n",
       "       [0.58333333, 0.33333333, 0.77966102, 0.83333333],\n",
       "       [0.80555556, 0.41666667, 0.81355932, 0.625     ],\n",
       "       [0.86111111, 0.33333333, 0.86440678, 0.75      ],\n",
       "       [1.        , 0.75      , 0.91525424, 0.79166667],\n",
       "       [0.58333333, 0.33333333, 0.77966102, 0.875     ],\n",
       "       [0.55555556, 0.33333333, 0.69491525, 0.58333333],\n",
       "       [0.5       , 0.25      , 0.77966102, 0.54166667],\n",
       "       [0.94444444, 0.41666667, 0.86440678, 0.91666667],\n",
       "       [0.55555556, 0.58333333, 0.77966102, 0.95833333],\n",
       "       [0.58333333, 0.45833333, 0.76271186, 0.70833333],\n",
       "       [0.47222222, 0.41666667, 0.6440678 , 0.70833333],\n",
       "       [0.72222222, 0.45833333, 0.74576271, 0.83333333],\n",
       "       [0.66666667, 0.45833333, 0.77966102, 0.95833333],\n",
       "       [0.72222222, 0.45833333, 0.69491525, 0.91666667],\n",
       "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
       "       [0.69444444, 0.5       , 0.83050847, 0.91666667],\n",
       "       [0.66666667, 0.54166667, 0.79661017, 1.        ],\n",
       "       [0.66666667, 0.41666667, 0.71186441, 0.91666667],\n",
       "       [0.55555556, 0.20833333, 0.6779661 , 0.75      ],\n",
       "       [0.61111111, 0.41666667, 0.71186441, 0.79166667],\n",
       "       [0.52777778, 0.58333333, 0.74576271, 0.91666667],\n",
       "       [0.44444444, 0.41666667, 0.69491525, 0.70833333]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJsUTyW0tI4k"
   },
   "outputs": [],
   "source": [
    "train, test, labels_train, labels_test = sklearn.model_selection.train_test_split(X, Y, train_size=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tnMkJK9NtI4s",
    "outputId": "2056b8fb-3e4d-4d0c-84a7-913a287c94e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CR9SiKXJtI4x",
    "outputId": "67c6f6f1-9904-4f30-b711-42a9b89514e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "6rzdGjygtI43",
    "outputId": "b4b33146-212b-4e26-869d-d1afee44c5ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 1, 1, 0, 2, 2, 2, 0, 2, 0, 2, 2, 0, 1, 2, 0, 2, 2, 1, 2,\n",
       "       0, 1, 1, 2, 2, 2, 2, 2, 0, 0, 2, 0, 0, 0, 1, 2, 1, 0, 1, 1, 0, 1,\n",
       "       2, 0, 1, 2, 0, 1, 1, 2, 2, 0, 1, 1, 2, 1, 2, 0, 2, 2, 0, 1, 2, 0,\n",
       "       1, 2, 0, 1, 1, 2, 0, 2, 0, 0, 2, 1, 0, 0, 1, 1, 2, 1, 0, 2, 2, 1,\n",
       "       2, 0, 0, 0, 0, 2, 1, 1, 0, 2, 1, 0, 0, 1, 1, 2, 1, 2, 2, 0, 1, 2,\n",
       "       0, 2, 2, 1, 2, 0, 2, 1, 1, 1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IsPwDC1xtI48"
   },
   "outputs": [],
   "source": [
    "D = np.c_[train,labels_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zi-zboxjtI5H",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('iris_train.csv', D, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "sXttUMAZtI5N",
    "outputId": "b37e06a9-48d4-4a0e-e1a1-6bfafcc7b1bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data::\n",
      "           0         1         2         3    4\n",
      "0   0.083333  0.666667  0.000000  0.041667  0.0\n",
      "1   0.583333  0.500000  0.593220  0.583333  1.0\n",
      "2   0.694444  0.416667  0.762712  0.833333  2.0\n",
      "3   0.333333  0.250000  0.576271  0.458333  1.0\n",
      "4   0.444444  0.416667  0.542373  0.583333  1.0\n",
      "5   0.027778  0.416667  0.050847  0.041667  0.0\n",
      "6   0.777778  0.416667  0.830508  0.833333  2.0\n",
      "7   0.722222  0.500000  0.796610  0.916667  2.0\n",
      "8   0.805556  0.666667  0.864407  1.000000  2.0\n",
      "9   0.194444  0.583333  0.084746  0.041667  0.0\n",
      "10  0.944444  0.416667  0.864407  0.916667  2.0\n",
      "11  0.250000  0.625000  0.084746  0.041667  0.0\n",
      "12  0.555556  0.541667  0.847458  1.000000  2.0\n",
      "13  0.944444  0.750000  0.966102  0.875000  2.0\n",
      "14  0.138889  0.416667  0.067797  0.000000  0.0\n",
      "15  0.638889  0.375000  0.610169  0.500000  1.0\n",
      "16  0.666667  0.208333  0.813559  0.708333  2.0\n",
      "17  0.305556  0.791667  0.050847  0.125000  0.0\n",
      "18  0.555556  0.333333  0.694915  0.583333  2.0\n",
      "19  0.694444  0.500000  0.830508  0.916667  2.0\n",
      "20  0.472222  0.583333  0.593220  0.625000  1.0\n",
      "21  0.444444  0.416667  0.694915  0.708333  2.0\n",
      "22  0.305556  0.583333  0.084746  0.125000  0.0\n",
      "23  0.472222  0.375000  0.593220  0.583333  1.0\n",
      "24  0.500000  0.375000  0.627119  0.541667  1.0\n",
      "Coefficients::\n",
      "[[-10.30815972   9.35872396 -16.22086864 -14.24153646]\n",
      " [  7.32421875  -3.25520833  10.75873941   7.32421875]\n",
      " [ 14.6484375   -0.81380208  14.56567797  16.68294271]]\n",
      "Predictions::\n",
      "[0. 2. 2. 2. 0. 2. 2. 2. 2. 1. 2. 2. 0. 1. 0.]\n",
      "Accuracy::\n",
      "0.6\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train Data::\n",
      "           0         1         2         3    4\n",
      "25  0.416667  0.291667  0.694915  0.750000  2.0\n",
      "26  0.472222  0.083333  0.677966  0.583333  2.0\n",
      "27  0.666667  0.458333  0.779661  0.958333  2.0\n",
      "28  0.500000  0.416667  0.661017  0.708333  2.0\n",
      "29  1.000000  0.750000  0.915254  0.791667  2.0\n",
      "30  0.083333  0.500000  0.067797  0.041667  0.0\n",
      "31  0.222222  0.625000  0.067797  0.083333  0.0\n",
      "32  0.555556  0.208333  0.677966  0.750000  2.0\n",
      "33  0.333333  0.625000  0.050847  0.041667  0.0\n",
      "34  0.222222  0.625000  0.067797  0.041667  0.0\n",
      "35  0.111111  0.500000  0.050847  0.041667  0.0\n",
      "36  0.222222  0.208333  0.338983  0.416667  1.0\n",
      "37  0.500000  0.250000  0.779661  0.541667  2.0\n",
      "38  0.250000  0.291667  0.491525  0.541667  1.0\n",
      "39  0.305556  0.583333  0.118644  0.041667  0.0\n",
      "40  0.333333  0.125000  0.508475  0.500000  1.0\n",
      "41  0.416667  0.250000  0.508475  0.458333  1.0\n",
      "42  0.111111  0.500000  0.101695  0.041667  0.0\n",
      "43  0.666667  0.458333  0.627119  0.583333  1.0\n",
      "44  0.666667  0.541667  0.796610  0.833333  2.0\n",
      "45  0.027778  0.375000  0.067797  0.041667  0.0\n",
      "46  0.388889  0.333333  0.525424  0.500000  1.0\n",
      "47  0.527778  0.333333  0.644068  0.708333  2.0\n",
      "48  0.166667  0.666667  0.067797  0.000000  0.0\n",
      "49  0.416667  0.291667  0.525424  0.375000  1.0\n",
      "Coefficients::\n",
      "[[ -5.42534722   7.32421875 -15.06223517 -19.53125   ]\n",
      " [ -1.62760417 -11.80013021   4.6345339    2.44140625]\n",
      " [ 11.66449653  -1.62760417  14.56567797  17.90364583]]\n",
      "Predictions::\n",
      "[0. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0.]\n",
      "Accuracy::\n",
      "0.4666666666666667\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train Data::\n",
      "           0         1         2         3    4\n",
      "50  0.666667  0.416667  0.677966  0.666667  1.0\n",
      "51  0.555556  0.291667  0.661017  0.708333  2.0\n",
      "52  0.666667  0.541667  0.796610  1.000000  2.0\n",
      "53  0.138889  0.583333  0.152542  0.041667  0.0\n",
      "54  0.722222  0.458333  0.661017  0.583333  1.0\n",
      "55  0.388889  0.416667  0.542373  0.458333  1.0\n",
      "56  0.583333  0.458333  0.762712  0.708333  2.0\n",
      "57  0.555556  0.541667  0.627119  0.625000  1.0\n",
      "58  0.583333  0.500000  0.728814  0.916667  2.0\n",
      "59  0.388889  1.000000  0.084746  0.125000  0.0\n",
      "60  0.611111  0.416667  0.813559  0.875000  2.0\n",
      "61  0.583333  0.291667  0.728814  0.750000  2.0\n",
      "62  0.194444  0.541667  0.067797  0.041667  0.0\n",
      "63  0.388889  0.333333  0.593220  0.500000  1.0\n",
      "64  0.416667  0.333333  0.694915  0.958333  2.0\n",
      "65  0.166667  0.416667  0.067797  0.041667  0.0\n",
      "66  0.472222  0.083333  0.508475  0.375000  1.0\n",
      "67  0.861111  0.333333  0.864407  0.750000  2.0\n",
      "68  0.000000  0.416667  0.016949  0.000000  0.0\n",
      "69  0.361111  0.375000  0.440678  0.500000  1.0\n",
      "70  0.694444  0.333333  0.644068  0.541667  1.0\n",
      "71  0.722222  0.458333  0.745763  0.833333  2.0\n",
      "72  0.250000  0.583333  0.067797  0.041667  0.0\n",
      "73  0.166667  0.208333  0.593220  0.666667  2.0\n",
      "74  0.055556  0.125000  0.050847  0.083333  0.0\n",
      "Coefficients::\n",
      "[[ -5.69661458   6.51041667 -13.40704449 -13.02083333]\n",
      " [  7.05295139  -6.10351562   8.27595339   0.81380208]\n",
      " [ -5.42534722  -3.66210938  -1.48967161   7.32421875]]\n",
      "Predictions::\n",
      "[0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
      "Accuracy::\n",
      "0.8\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train Data::\n",
      "           0         1         2         3    4\n",
      "75  0.194444  0.625000  0.101695  0.208333  0.0\n",
      "76  0.555556  0.375000  0.779661  0.708333  2.0\n",
      "77  0.472222  0.291667  0.694915  0.625000  1.0\n",
      "78  0.027778  0.500000  0.050847  0.041667  0.0\n",
      "79  0.194444  0.583333  0.101695  0.125000  0.0\n",
      "80  0.666667  0.458333  0.576271  0.541667  1.0\n",
      "81  0.333333  0.166667  0.457627  0.375000  1.0\n",
      "82  0.611111  0.416667  0.711864  0.791667  2.0\n",
      "83  0.500000  0.333333  0.508475  0.500000  1.0\n",
      "84  0.222222  0.583333  0.084746  0.041667  0.0\n",
      "85  0.555556  0.583333  0.779661  0.958333  2.0\n",
      "86  0.583333  0.333333  0.779661  0.833333  2.0\n",
      "87  0.500000  0.333333  0.627119  0.458333  1.0\n",
      "88  0.833333  0.375000  0.898305  0.708333  2.0\n",
      "89  0.138889  0.583333  0.101695  0.041667  0.0\n",
      "90  0.222222  0.541667  0.118644  0.166667  0.0\n",
      "91  0.250000  0.875000  0.084746  0.000000  0.0\n",
      "92  0.194444  0.500000  0.033898  0.041667  0.0\n",
      "93  0.944444  0.333333  0.966102  0.791667  2.0\n",
      "94  0.555556  0.125000  0.576271  0.500000  1.0\n",
      "95  0.166667  0.166667  0.389831  0.375000  1.0\n",
      "96  0.194444  0.666667  0.067797  0.041667  0.0\n",
      "97  0.805556  0.500000  0.847458  0.708333  2.0\n",
      "98  0.388889  0.375000  0.542373  0.500000  1.0\n",
      "99  0.416667  0.833333  0.033898  0.041667  0.0\n",
      "Coefficients::\n",
      "[[-10.30815972   6.91731771 -16.05534958 -14.6484375 ]\n",
      " [  0.54253472 -12.61393229   5.62764831   3.25520833]\n",
      " [ -1.89887153 -10.17252604   2.81382415   5.28971354]]\n",
      "Predictions::\n",
      "[0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
      "Accuracy::\n",
      "0.8\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train Data::\n",
      "            0         1         2         3    4\n",
      "100  0.388889  0.750000  0.118644  0.083333  0.0\n",
      "101  0.527778  0.083333  0.593220  0.583333  1.0\n",
      "102  0.361111  0.416667  0.525424  0.500000  1.0\n",
      "103  0.805556  0.416667  0.813559  0.625000  2.0\n",
      "104  0.583333  0.375000  0.559322  0.500000  1.0\n",
      "105  0.388889  0.208333  0.677966  0.791667  2.0\n",
      "106  0.666667  0.416667  0.711864  0.916667  2.0\n",
      "107  0.305556  0.791667  0.118644  0.125000  0.0\n",
      "108  0.388889  0.250000  0.423729  0.375000  1.0\n",
      "109  0.944444  0.250000  1.000000  0.916667  2.0\n",
      "110  0.194444  0.416667  0.101695  0.041667  0.0\n",
      "111  0.527778  0.583333  0.745763  0.916667  2.0\n",
      "112  0.361111  0.333333  0.661017  0.791667  2.0\n",
      "113  0.194444  0.000000  0.423729  0.375000  1.0\n",
      "114  0.472222  0.416667  0.644068  0.708333  2.0\n",
      "115  0.138889  0.458333  0.101695  0.041667  0.0\n",
      "116  0.583333  0.333333  0.779661  0.875000  2.0\n",
      "117  0.361111  0.416667  0.593220  0.583333  1.0\n",
      "118  0.361111  0.291667  0.542373  0.500000  1.0\n",
      "119  0.194444  0.125000  0.389831  0.375000  1.0\n",
      "120  0.083333  0.583333  0.067797  0.083333  0.0\n",
      "121  0.083333  0.458333  0.084746  0.041667  0.0\n",
      "122  0.166667  0.458333  0.084746  0.041667  0.0\n",
      "123  0.916667  0.416667  0.949153  0.833333  2.0\n",
      "124  0.138889  0.416667  0.067797  0.083333  0.0\n",
      "Coefficients::\n",
      "[[ -9.765625    10.57942708 -16.22086864 -15.86914062]\n",
      " [ -2.44140625  -8.54492187   2.31726695  -2.03450521]\n",
      " [  8.95182292   1.22070313  14.23463983  23.60026042]]\n",
      "Predictions::\n",
      "[0. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0.]\n",
      "Accuracy::\n",
      "0.4666666666666667\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Train Data::\n",
      "            0         1         2         3    4\n",
      "125  0.222222  0.750000  0.101695  0.041667  0.0\n",
      "126  0.333333  0.916667  0.067797  0.041667  0.0\n",
      "127  0.361111  0.208333  0.491525  0.416667  1.0\n",
      "128  0.305556  0.708333  0.084746  0.041667  0.0\n",
      "129  0.222222  0.750000  0.152542  0.125000  0.0\n",
      "130  0.333333  0.166667  0.474576  0.416667  1.0\n",
      "131  0.194444  0.625000  0.050847  0.083333  0.0\n",
      "132  0.750000  0.500000  0.627119  0.541667  1.0\n",
      "133  0.638889  0.416667  0.576271  0.541667  1.0\n",
      "134  0.611111  0.500000  0.694915  0.791667  2.0\n",
      "Coefficients::\n",
      "[[ -5.23070146   7.02015197 -10.07878248 -10.73670301]\n",
      " [ -4.68010131 -10.32375289  -3.02363474  -4.12950116]\n",
      " [  0.55060015  -4.12950116   0.67191883   2.47770069]]\n",
      "Predictions::\n",
      "[0. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0.]\n",
      "Accuracy::\n",
      "0.4666666666666667\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "\n",
    "# reading the csv in chunks\n",
    "chunksize = 25\n",
    "for chunk in pd.read_csv('iris_train.csv', header=None, chunksize=chunksize):\n",
    "    train_sub = chunk\n",
    "    print('Train Data::')\n",
    "    print(train_sub)\n",
    "    Y=train_sub[4]\n",
    "    X=train_sub.drop([4], axis=1)\n",
    "    clf = linear_model.SGDClassifier() # using the classifier\n",
    "    clf.partial_fit(X,Y, classes=np.unique(Y))\n",
    "    print('Coefficients::')\n",
    "    print(clf.coef_)\n",
    "    pred=clf.predict(test)\n",
    "    print('Predictions::')\n",
    "    print(pred)\n",
    "    print('Accuracy::')\n",
    "    print(accuracy_score(pred, labels_test))\n",
    "    print('+'*55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_7K0_6datI5T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u-BZ68qHtI5Y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "updatable_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
